{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "595f06ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\vscode_projects\\AQUA\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from huggingface_hub import hf_hub_download\n",
    "import onnxruntime as ort\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48ec37f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено документов: 335919\n"
     ]
    }
   ],
   "source": [
    "path_to_pdf = \"data/pdf\"\n",
    "path_to_csv = \"data/csv\"\n",
    "\n",
    "def read_pdf(pdf_folder):\n",
    "    docs = []\n",
    "    for file in os.listdir(pdf_folder):\n",
    "        if file.endswith(\".pdf\"):\n",
    "            path = os.path.join(pdf_folder, file)\n",
    "            reader = PdfReader(path)\n",
    "            for i, page in enumerate(reader.pages):\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    docs.append(\n",
    "                        Document(\n",
    "                            page_content=text,\n",
    "                            metadata={\"source\": file, \"page\": i + 1}\n",
    "                        )\n",
    "                    )\n",
    "    return docs\n",
    "\n",
    "\n",
    "def read_csv(csv_folder):\n",
    "    docs = []\n",
    "    for file in os.listdir(csv_folder):\n",
    "        if file.endswith(\".csv\"):\n",
    "            path = os.path.join(csv_folder, file)\n",
    "            with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "                reader = csv.reader(f)\n",
    "                header = next(reader, None)  # первая строка (заголовки)\n",
    "                for i, row in enumerate(reader):\n",
    "                    # собираем строку вида \"col1: val1, col2: val2, ...\"\n",
    "                    if header:\n",
    "                        text = \", \".join([f\"{col}: {val}\" for col, val in zip(header, row)])\n",
    "                    else:\n",
    "                        text = \", \".join(row)\n",
    "                    docs.append(\n",
    "                        Document(\n",
    "                            page_content=text,\n",
    "                            metadata={\"source\": file, \"row\": i + 1}\n",
    "                        )\n",
    "                    )\n",
    "    return docs\n",
    "\n",
    "\n",
    "# Load all documents\n",
    "all_docs = read_pdf(path_to_pdf) + read_csv(path_to_csv)\n",
    "print(f\"Загружено документов: {len(all_docs)}\")\n",
    "\n",
    "# Split on chunks with saving the metadata\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunked_docs = splitter.split_documents(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "377e06ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(docs, model_name=\"sentence-transformers/all-MiniLM-L6-v2\", batch_size=256):\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    texts = [doc.page_content for doc in docs]\n",
    "    metas = [doc.metadata for doc in docs]\n",
    "\n",
    "    for start in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[start:start+batch_size]\n",
    "        batch_metas = metas[start:start+batch_size]\n",
    "\n",
    "        batch_embeddings = model.encode(\n",
    "            batch_texts,\n",
    "            batch_size=batch_size,\n",
    "            convert_to_numpy=True,\n",
    "            show_progress_bar=False\n",
    "        )\n",
    "\n",
    "        # Возвращаем пачку как генератор\n",
    "        for i, emb in enumerate(batch_embeddings):\n",
    "            yield {\n",
    "                \"embedding\": emb,\n",
    "                \"content\": batch_texts[i],\n",
    "                \"metadata\": batch_metas[i]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33fe6628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добавлено 524603 эмбеддингов в индекс\n",
      "Размер индекса: 524604\n"
     ]
    }
   ],
   "source": [
    "# Создаём FAISS-индекс\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "d = model.get_sentence_embedding_dimension()\n",
    "index = faiss.IndexFlatL2(d)\n",
    "\n",
    "texts, metas = [], []\n",
    "\n",
    "# Генеративная обработка\n",
    "for i, item in enumerate(generate_embeddings(chunked_docs, batch_size=256)):\n",
    "    index.add(np.array([item[\"embedding\"]], dtype=\"float32\"))\n",
    "    texts.append(item[\"content\"])\n",
    "    metas.append(item[\"metadata\"])\n",
    "\n",
    "else:\n",
    "    print(f\"Добавлено {i} эмбеддингов в индекс\")\n",
    "\n",
    "print(\"Размер индекса:\", index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44df8a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Поиск релевантых документов\n",
    "def search(query, model, index, texts, metas, top_k=5):\n",
    "    query_emb = model.encode([query], convert_to_numpy=True).astype(\"float32\")\n",
    "    distances, indices = index.search(query_emb, top_k)\n",
    "    return [\n",
    "        {\"text\": texts[i], \"metadata\": metas[i], \"distance\": float(distances[0][j])}\n",
    "        for j, i in enumerate(indices[0])\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f07cd7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, retrieved_docs):\n",
    "    context = \"\\n\\n\".join([doc[\"text\"] for doc in retrieved_docs])\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "You are an expert in SQL query optimization. \n",
    "Always use the retrieved context to improve SQL queries. \n",
    "\n",
    "Context may include: \n",
    "- Database schemas, table structures \n",
    "- Existing indexes and constraints \n",
    "- Query execution plans or performance notes \n",
    "\n",
    "Your responsibilities:\n",
    "1. Analyze the original SQL query provided by the user.\n",
    "2. Use the retrieved context to suggest the best possible optimization.\n",
    "3. Output the optimized SQL query in a code block.\n",
    "4. Explain why this query is more efficient, referencing the context when relevant.\n",
    "5. If multiple optimization strategies are possible, pick the best one and briefly mention alternatives.\n",
    "6. Ensure the optimized query always produces the same results as the original.\n",
    "\n",
    "Format your answer strictly as follows:\n",
    "\n",
    "**Optimized Query:**\n",
    "```sql\n",
    "-- optimized SQL here\n",
    "\n",
    "Question: {query} \\n\n",
    "Context: {context}\n",
    "\n",
    "\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81e50cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model directly\n",
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"codeparrot/codeparrot\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"codeparrot/codeparrot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692de55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query, retrieved_docs):\n",
    "    prompt = build_prompt(query, retrieved_docs)\n",
    "\n",
    "    # Токенизируем входные данные\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    outputs = model.generate(**inputs, max_new_tokens=300)\n",
    "    \n",
    "    # Декодируем и возвращаем результат\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5e45f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Что такое машинное обучение?\"\n",
    "retrieved = search(query, model, index, texts, metas, top_k=5)\n",
    "answer = generate_answer(query, retrieved)\n",
    "\n",
    "print(\"Ответ:\", answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
